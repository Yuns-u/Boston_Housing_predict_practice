{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice_Boston_Housing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYcO+cRNyWa9yfAUaOqS6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuns-u/Boston_Housing_predict_practice/blob/main/Practice_Boston_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPZ5PqvU1gar"
      },
      "source": [
        "# Practice Deep Learning on regression problem\n",
        "\n",
        "회귀문제를 딥러닝모델을 통해 해결해보고자 한다.\n",
        "해결하고자 하는 문제는 아래와 같다.\n",
        "\n",
        "1. Boston의 주택가격을 예측하는 딥러닝 모델을 만들어보기\n",
        "2. 딥러닝이 아닌 머신러닝모델을 사용해서 같은 문제를 풀어보고 그 결과를 비교해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phidn2gU1-BR"
      },
      "source": [
        "## 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5PMCToj1CSM"
      },
      "source": [
        "# 필요한 모듈 불러오기\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWqxAqmX1Trt"
      },
      "source": [
        "# 데이터 불러오기\n",
        "boston_housing = tf.keras.datasets.boston_housing\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zCv9H8c2V7W"
      },
      "source": [
        "# 각 데이터셋의 shape 확인하기 : feature 수에 비해 데이터의 규모가 작은 것으로 보인다.\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeH-PxyK3jdZ"
      },
      "source": [
        "X_train \n",
        "#numpy.array형식이라 pandas.DataFrame처럼 상위 몇 개를 보는 방법을 사용할 수 없었다.\n",
        "#하지만 pandas의 메모리 소모량을 생각했을 때 불러오지 않고 처리를 해보고 싶기도하고 pandas를 사용하지 않고 head처럼 처리할 수 있는 방법이 있을 것 같다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKANSboR3n0I"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nu1QDs62vxL"
      },
      "source": [
        "# 데이터 정규화하기\n",
        "# 데이터 정규화에 필요한 모듈 불러오기\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train) #훈련해야하는 수치들을 정규화한다.\n",
        "X_test = scaler.transform(X_test) #훈련데이터가 정규화되었으므로 예측의 기반이 될 테스트데이터셋도 정규화해준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4QAhIxl2Dze"
      },
      "source": [
        "## 신경망을 통해 regression 문제 해결하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yr9UWcC2HAt"
      },
      "source": [
        "#모델 만들기\n",
        "model_network = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Dense(64, activation='relu', input_dim=13),\n",
        " tf.keras.layers.Dropout(0.2),\n",
        " tf.keras.layers.Dense(16, activation='relu'),\n",
        " tf.keras.layers.Dense(1, activation='relu')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPwMoKe98QE4"
      },
      "source": [
        "#모델에 컴파일러 적용하여 옵티마이저, 손실함수 등 설정해주기\n",
        "model_network.compile(optimizer='adam', \n",
        "              loss='mse',\n",
        "              metrics=['accuracy','mse','mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-T_yrxs9QMH"
      },
      "source": [
        "#학습 실행해주기\n",
        "history = model_network.fit(X_train, y_train, epochs=30, batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJffX_QI_-BM"
      },
      "source": [
        "#모델평가하기\n",
        "#R2 값으로 모델의 설명력 확인해보기\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "y_pred = model_network.predict(X_test)\n",
        "\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAbvDe_Y2HkK"
      },
      "source": [
        "## 신경망이 아닌 머신러닝모델을 사용해서 regression 문제 해결하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhaYUbvq2MJT"
      },
      "source": [
        "#선형회귀모델로 머신러닝모델 만들기\n",
        "\n",
        "#필요한 모듈 불러오기\n",
        "from sklearn.linear_model import LinearRegression #모델 만들기\n",
        "from sklearn.metrics import mean_squared_error #위의 신경망과 비교하기 위한 모듈\n",
        "from sklearn.metrics import mean_absolute_error #위의 신경망과 비교하기 위한 모듈\n",
        "\n",
        "#선형회귀모델 만들기\n",
        "model = LinearRegression()\n",
        "#모델 학습시키기: 여러 feature들로 구성되어있으므로 다중선형회귀모델일 것이다.\n",
        "model.fit(X_train, y_train)\n",
        "#예측하기\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#예측값과 실제값 비교하여 평가하기\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE : {mae}')\n",
        "print(f'MSE : {mse}')\n",
        "print(f'R2 : {r2}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKO45sG02NA_"
      },
      "source": [
        "## 두 모델을 비교해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkqvV-fGkkP"
      },
      "source": [
        "- 신경망모델의 r2값과 다중선형회귀모델의 r2값을 비교해보면 다중선형회귀모델의 값이 더 높기 때문에 이 회귀문제에 대한 데이터의 설명력은 다중선형회귀모델이 더 좋다고 할 수 있다.\n",
        "\n",
        "- 신경망모델의 경우 30 epoche가 될 때 쯤에서야 다중선형회귀모델과 유사한 평가지표(mse, mae)값이 나온 것을 확인할 수 있다. `loss: 21.3019 - accuracy: 0.0000e+00 - mse: 21.3019 - mae: 3.3147`에서 알 수 있다.\n",
        "\n",
        "- 신경망 모델에서 epoche가 크다고 해서 성능이 항상 좋게 나오는 것은 아니다. 어느정도 이상에서는 epoche 횟수를 늘리는 것이 유의미한 성능 향상을 불러오는 것이 아니기 때문이다.\n",
        "\n",
        "- 자원 리소스 측면에서 신경망 모델을 쓰는 것이 더 비효율적일 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7OXPD8WYIiR"
      },
      "source": [
        "# 신경망에 교차검증(cross-validation) 적용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jska63MIYldT"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K61x0zLLYISe"
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS091gZ8bidV"
      },
      "source": [
        "## 필요한 라이브러리들을 Import 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzWger0PbmPf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu227a0UcOwT"
      },
      "source": [
        "## `KFold`를 통해 학습 데이터셋을 몇 개로 나눌 것인지 결정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zskx-N6cW4m"
      },
      "source": [
        "#두 교차검증을 모두 5개로 나누어 볼 것이다.\n",
        "kf = KFold(n_splits=5)\n",
        "skf = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
        "#훈련데이터는 feature수가 13개인 404개라는 것을 데이터 불러오기 및 전처리에서 살펴보았다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliMajhBdF8U"
      },
      "source": [
        "## 모델만들기\n",
        "위의 모델인 model_network를 불러와 재학습을 시켜주는 방법도 있겠지만 이미 학습이 된 상태이므로 비슷한 모델을 만들어볼 것이다.\n",
        "단, 모델을 만드는 방법을 연습하기 위해 모델 함수에 층을 입력하는 방법이 아닌, 모델에 add를 사용하여 층을 넣어주는 방식으로 해보고자 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZQDUc92dIOz"
      },
      "source": [
        "#필요한 모듈 불러오기\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAIMuBrd_wL"
      },
      "source": [
        "#모델 만들기\n",
        "model_cv = Sequential()\n",
        "model_cv.add(Dense(64, activation='relu'))\n",
        "model_cv.add(Dense(64, activation='relu'))\n",
        "model_cv.add(Dense(1)) #회귀문제로 하나의 값만 도출하면 되기 때문에 출력노드의 수를 1로 해준다.\n",
        "\n",
        "#모델 컴파일하기\n",
        "model_cv.compile(loss='mean_squared_logarithmic_error',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC0qnBlTewj2"
      },
      "source": [
        "#모델 학습시키기\n",
        "model_cv.fit(X_train, y_train, epochs=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAlxTH-5fC9U"
      },
      "source": [
        "## 교차검증 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_3RHgvlgQkt"
      },
      "source": [
        "#k개로 나눠줄 때 데이터와 라벨의 값과 일치하도록 분리해주어야하지만 넘파이에서는 그러한 index가 없다.\n",
        "#따라서 numpy.array로 되어있는 X_train,y_train을 pandas.DataFrame의 형식으로 바꿔준 뒤 학습시키는 것이 좋을 것이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLB2kbHsg_TG"
      },
      "source": [
        "#학습데이터셋을 데이터프레임으로 바꿔주기\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVqWD8DRfP5g"
      },
      "source": [
        "#학습데이터셋을 k개의 dataset으로 나눠주기\n",
        "\n",
        "for train_index, val_index in kf.split(np.zeros(X_train.shape[0]),y_train):\n",
        "  folded_X_train = X_train.iloc[train_index,:]\n",
        "  folded_X_train_label = y_train.iloc[train_index,:]\n",
        "  validation_X_train = X_train.iloc[val_index,:]\n",
        "  validation_X_train_label = y_train.iloc[val_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFkOFSh4iB03"
      },
      "source": [
        "#데이터가 잘 나뉘어졌는지 확인해보기\n",
        "folded_X_train_label.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3peiT4OiM4W"
      },
      "source": [
        "print(folded_X_train)\n",
        "print(folded_X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skctuweOhLf2"
      },
      "source": [
        "#교차검증으로 모델 학습시키기\n",
        "model_cv.fit(folded_X_train, folded_X_train_label,\n",
        "             epochs=10,\n",
        "             batch_size=64,\n",
        "             validation_data=(validation_X_train, validation_X_train_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrqv2rvshz2F"
      },
      "source": [
        "epoch를 더 많이 돌린다고해서 항상 손실함수값이 작아지는 것이 아니라 변동한다는 것을 위의 수치들을 통해 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR5MySdVjn6-"
      },
      "source": [
        "#모델 컴파일하기\n",
        "#이 때, 어떤 손실함수를 사용할 것인지 여러 가지를 실험해볼 수 있다.\n",
        "#loss='binary_crossentropy'\n",
        "model_cv.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model_cv.fit(folded_X_train, folded_X_train_label,\n",
        "             epochs=10,\n",
        "             batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b_wUYYqieaB"
      },
      "source": [
        "#모델 컴파일하기\n",
        "#이 때, 어떤 손실함수를 사용할 것인지 여러 가지를 실험해볼 수 있다.\n",
        "#loss='mean_squared_error'\n",
        "model_cv.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_cv.fit(folded_X_train, folded_X_train_label,\n",
        "             epochs=10,\n",
        "             batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy4vtZRejz7c"
      },
      "source": [
        "#결과 확인해보기\n",
        "results = model_cv.evaluate(X_test, y_test, batch_size=32)\n",
        "print('mse of test loss:',results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}